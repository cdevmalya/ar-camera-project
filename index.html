<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <!-- Name of your awesome camera app -->
    <title>AR Camera App</title>

    <script type="text/javascript" src="cv.js"></script> 
    <script type="text/javascript" src="aruco.js"></script> 
    <!-- Link to your main style sheet-->
    <link rel="stylesheet" href="style.css">
    <script>
        var my_video, my_canvas, my_canvas2, context, context2, image, imageData, detector;
          function onLoad() {
              my_video = document.getElementById("video");
              my_canvas = document.getElementById("canvas");
              context = my_canvas.getContext("2d");
              my_canvas2 = document.getElementById("canvas2");
              context2 = my_canvas2.getContext("2d");

            //   context2.transform(1, 0.2, 0.8, 1, 0, 0);
              context2.strokeStyle = "black";
              context2.font = "24px serif";

              // make a square canvas - depending on the smaller of the window width or height
              if (window.innerWidth > window.innerHeight ){
                width = window.innerHeight;
              } else{
                width = window.innerWidth;
              }

              my_canvas.style.width = width + "px";
              my_canvas.style.height = 1.3*width  + "px";

              my_canvas.width = parseInt(my_canvas.style.width);
              my_canvas.height = parseInt(my_canvas.style.height);


              // canvas2 has same pixel dimensions
              my_canvas2.width = parseInt(my_canvas.style.width);
              my_canvas2.height = parseInt(my_canvas.style.height);

              context2.strokeStyle = "black";
              context2.font = "24px serif";
  
              // Set constraints for the video stream
              var constraints = { video: { facingMode: "environment" }, audio: false };
              function cameraStart() {
                  navigator.mediaDevices
                      .getUserMedia(constraints)
                      .then(function(stream) {
                      track = stream.getTracks()[0];
                      my_video.srcObject = stream;
                  })
                  .catch(function(error) {
                      console.error("Oops. Something is broken.", error);
                  });
              }
              cameraStart();
              detector = new AR.Detector();
              requestAnimationFrame(tick);
            //   setInterval(() => requestAnimationFrame(tick), 50);
          }
  
          function tick(){
              requestAnimationFrame(tick);
            //   setInterval(() => requestAnimationFrame(tick), 50); 
              if (my_video.readyState === my_video.HAVE_ENOUGH_DATA){
                snapshot();

                var markers = detector.detect(imageData);
                drawCorners(markers);
              }
          }
          
          function snapshot(){
              context.drawImage(my_video, 0, 0, my_canvas.width, my_canvas.height); //this can be used to fix the elongation currently its covering the window screen which makes the image longer
              imageData = context.getImageData(0, 0, my_canvas.width, my_canvas.height);
              
          }
  
          function drawCorners(markers){
              let corners, corner, i, j;
      
              context.lineWidth = 3;
  
              for (i = 0; i !== markers.length; ++ i){
                corners = markers[i].corners;
                context.strokeStyle = "red";
                context.beginPath();
              
                for (j = 0; j !== corners.length; ++ j){
                corner = corners[j];
                context.moveTo(corner.x, corner.y);
                corner = corners[(j + 1) % corners.length];
                context.lineTo(corner.x, corner.y);
                }
    
                context.stroke();
                context.closePath();
                
                //   context.strokeStyle = "green";
                //   context.strokeRect(corners[0].x - 2, corners[0].y - 2, 40, 40);
                //   context.drawImage(image,corners[0].x - 2, corners[0].y - 2);
                //   context2.drawImage(image,10,10);
                //   context2.translate(corners[3].x, corners[3].y); //checking if changing origin of canvas fixed transform offset
                // context2.setTransform(1, 0, 0, 1, 0, 0);
                // context2.clearRect(0,0,my_canvas2.width,my_canvas2.height);
                // context2.fillText("Hello there!",corners[3].x, corners[3].y);
                // context2.fillText("This is a test.",corners[3].x, corners[3].y + 30);
                // context2.fillText("Let us see if it works",corners[3].x, corners[3].y + 60);
            }
            context2.setTransform(1, 0, 0, 1, 0, 0);
            context2.clearRect(0,0,my_canvas2.width,my_canvas2.height);
            context2.fillText("Hello there!",markers[0].corners[3].x, markers[0].corners[3].y);
            context2.fillText("This is a test.",markers[0].corners[3].x, markers[0].corners[3].y + 30);
            context2.fillText("Let us see if it works",markers[0].corners[3].x, markers[0].corners[3].y + 60);
          }
          window.onload = onLoad;
      </script>
</head>

<body>
    <!-- Camera view -->
    <!-- <video id="video" autoplay playsinline hidden></video> -->
    <video id="video" autoplay playsinline></video>
    <!-- Camera sensor -->
    <!-- <canvas id="canvas" style="width:640px; height:480px;"></canvas> -->
    <canvas id="canvas" style="z-index: 1; position:absolute; left:0px; top:0px;"></canvas>
    <!-- <canvas id="canvas2" style="z-index: 2; position:absolute; left:0px; top:0px;" width="960px" height="800px"></canvas> -->
    <canvas id="canvas2" style="z-index: 2; position:absolute; left:0px; top:0px;"></canvas>
</body>
</html>
